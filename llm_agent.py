import os
import json
from typing import Dict, Any, Optional
from dotenv import load_dotenv
import openai
from tools import ToolManager
from logger import get_logger

# è·å–æ—¥å¿—è®°å½•å™¨
logger = get_logger()

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class LLMStockAgent:
    def __init__(self, news_api_key: str, model_name: str = "gpt-4"):
        self.model_name = model_name
        self.tool_manager = ToolManager(news_api_key)
        self.openai_client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        # ç³»ç»Ÿæç¤ºè¯ - å®šä¹‰Agentçš„è§’è‰²å’Œè¡Œä¸ºå‡†åˆ™
        self.system_prompt = self._create_system_prompt()

        # å¯¹è¯å†å²
        self.conversation_history = [{"role": "system", "content": self.system_prompt}]

    def _create_system_prompt(self) -> str:
        """åˆ›å»ºç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰Agentçš„è¡Œä¸ºæ–¹å¼"""
        tool_descriptions = self.tool_manager.get_all_tool_descriptions()

        # è·å–å½“å‰ç³»ç»Ÿæ—¥æœŸ
        from datetime import datetime

        current_date = datetime.now().strftime("%Y-%m-%d")

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æAIåŠ©æ‰‹ï¼Œä¸“æ³¨äºåŸºäºçœŸå®æ•°æ®çš„å®¢è§‚åˆ†æã€‚

ä»Šå¤©çš„æ—¥æœŸæ˜¯: {current_date}

**æ ¸å¿ƒåŸåˆ™ï¼š**
1. åªåŸºäºå·¥å…·è¿”å›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æï¼Œç»ä¸ç¼–é€ æ•°æ®
2. æ˜ç¡®åŒºåˆ†äº‹å®å’Œæ¨æµ‹ï¼Œé¿å…è¿‡åº¦è§£è¯»
3. æ‰¿è®¤æ•°æ®å±€é™æ€§ï¼Œä¸åšç»å¯¹é¢„æµ‹
4. æä¾›é£é™©æç¤ºå’Œå…è´£å£°æ˜

**å¯ç”¨å·¥å…·ï¼š**
{tool_descriptions}

**åˆ†ææ¡†æ¶ï¼š**
1. **æ•°æ®æ”¶é›†é˜¶æ®µ**ï¼š
   - æ˜ç¡®ç”¨æˆ·éœ€æ±‚ï¼Œç¡®å®šæ‰€éœ€æ•°æ®ç±»å‹
   - ç³»ç»Ÿæ€§æ”¶é›†ç›¸å…³æ•°æ®ï¼ˆä»·æ ¼ã€è´¢åŠ¡ã€æŠ€æœ¯æŒ‡æ ‡ã€æ–°é—»ï¼‰
   - éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œæ—¶æ•ˆæ€§

2. **å®¢è§‚åˆ†æé˜¶æ®µ**ï¼š
   - æŠ€æœ¯é¢ï¼šåŸºäºæŒ‡æ ‡æ•°å€¼è¿›è¡Œè¶‹åŠ¿åˆ¤æ–­
   - åŸºæœ¬é¢ï¼šåŸºäºè´¢åŠ¡æ•°æ®è¯„ä¼°å…¬å¸å¥åº·åº¦
   - å¸‚åœºæƒ…ç»ªï¼šåŸºäºæ–°é—»å†…å®¹åˆ†æå¸‚åœºé¢„æœŸ
   - é£é™©è¯„ä¼°ï¼šè¯†åˆ«æ½œåœ¨é£é™©å› ç´ 

3. **ç»“è®ºè¡¨è¿°**ï¼š
   - æ˜ç¡®æ ‡æ³¨æ•°æ®æ¥æºå’Œæ—¶é—´
   - åŒºåˆ†"æ•°æ®æ˜¾ç¤º"å’Œ"å¯èƒ½æ„å‘³ç€"
   - æä¾›å¤šç§æƒ…æ™¯åˆ†æ
   - å¼ºè°ƒæŠ•èµ„é£é™©å’Œä¸ç¡®å®šæ€§

**å·¥å…·è°ƒç”¨æ ¼å¼ï¼š**
<tool_call>
{{
  "name": "å·¥å…·åç§°",
  "parameters": {{
    "å‚æ•°1": "å€¼1",
    "å‚æ•°2": "å€¼2"
  }}
}}
</tool_call>

**ä¸¥æ ¼è¦æ±‚ï¼š**
- ç¦æ­¢ç¼–é€ ä»»ä½•æ•°æ®æˆ–æŒ‡æ ‡å€¼
- å¦‚æœå·¥å…·è¿”å›é”™è¯¯æˆ–ç©ºæ•°æ®ï¼Œå¿…é¡»å¦‚å®è¯´æ˜
- ä¸å¾—å¯¹è‚¡ä»·åšå‡ºå…·ä½“çš„æ¶¨è·Œé¢„æµ‹
- å¿…é¡»åœ¨åˆ†æç»“å°¾åŒ…å«é£é™©æç¤º
- æ‰¿è®¤åˆ†æçš„å±€é™æ€§å’Œæ—¶æ•ˆæ€§

**æ ‡å‡†ç»“å°¾æ¨¡æ¿ï¼š**
"ä»¥ä¸Šåˆ†æåŸºäº{{æ•°æ®æ—¶é—´}}çš„å…¬å¼€æ•°æ®ï¼Œä»…ä¾›å‚è€ƒã€‚è‚¡å¸‚æŠ•èµ„å­˜åœ¨é£é™©ï¼Œè¿‡å¾€è¡¨ç°ä¸ä»£è¡¨æœªæ¥ç»“æœã€‚æŠ•èµ„è€…åº”ç»“åˆè‡ªèº«æƒ…å†µè°¨æ…å†³ç­–ï¼Œå¿…è¦æ—¶å’¨è¯¢ä¸“ä¸šæŠ•èµ„é¡¾é—®ã€‚"
"""

    def _parse_tool_call(self, response: str) -> Optional[Dict[str, Any]]:
        """è§£æå¤§æ¨¡å‹çš„å“åº”ï¼Œæå–å·¥å…·è°ƒç”¨æŒ‡ä»¤"""
        start_tag = "<tool_call>"
        end_tag = "</tool_call>"

        start_idx = response.find(start_tag)
        end_idx = response.find(end_tag)

        if start_idx == -1 or end_idx == -1:
            logger.debug("æœªåœ¨LLMå“åº”ä¸­æ‰¾åˆ°å·¥å…·è°ƒç”¨æ ‡è®°")
            return None

        try:
            tool_call_str = response[start_idx + len(start_tag) : end_idx].strip()
            logger.debug(f"æå–åˆ°å·¥å…·è°ƒç”¨æ–‡æœ¬: {tool_call_str[:100]}...")
            result = json.loads(tool_call_str)
            logger.debug(
                f"æˆåŠŸè§£æå·¥å…·è°ƒç”¨JSON: {result['name'] if 'name' in result else 'æœªçŸ¥å·¥å…·'}"
            )
            return result
        except json.JSONDecodeError:
            logger.error("è§£æå·¥å…·è°ƒç”¨JSONå¤±è´¥")
            return None

    def _run_tool(self, tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶éªŒè¯æ•°æ®è´¨é‡"""
        tool_name = tool_call.get("name")
        parameters = tool_call.get("parameters", {})

        logger.info(f"å‡†å¤‡æ‰§è¡Œå·¥å…·: {tool_name}")
        logger.debug(f"å·¥å…·å‚æ•°: {json.dumps(parameters)}")

        if not tool_name:
            logger.warning("æœªæŒ‡å®šå·¥å…·åç§°")
            return {"error": "æœªæŒ‡å®šå·¥å…·åç§°"}

        tool = self.tool_manager.get_tool(tool_name)
        if not tool:
            logger.warning(f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
            return {"error": f"æœªçŸ¥å·¥å…·: {tool_name}"}

        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œå·¥å…·: {tool_name}")
            result = tool.run(**parameters)

            # æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥
            validated_result = self._validate_tool_result(tool_name, result, parameters)
            return validated_result
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "tool": tool_name,
                "parameters": parameters,
                "error": str(e),
                "data_quality": "error",
            }

    def _validate_tool_result(
        self, tool_name: str, result: Any, parameters: Dict
    ) -> Dict[str, Any]:
        """éªŒè¯å·¥å…·è¿”å›ç»“æœçš„è´¨é‡å’Œå®Œæ•´æ€§"""
        validation_info = {
            "status": "success",
            "tool": tool_name,
            "parameters": parameters,
            "result": result,
            "data_quality": "good",
            "validation_notes": [],
        }

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if isinstance(result, dict) and "error" in result:
                validation_info["data_quality"] = "error"
                validation_info["validation_notes"].append(
                    f"å·¥å…·è¿”å›é”™è¯¯: {result['error']}"
                )
                return validation_info

            # æ ¹æ®å·¥å…·ç±»å‹è¿›è¡Œç‰¹å®šéªŒè¯
            if tool_name == "get_historical_data":
                if isinstance(result, dict):
                    if "period_summary" in result:
                        summary = result["period_summary"]
                        if summary.get("total_days", 0) == 0:
                            validation_info["data_quality"] = "poor"
                            validation_info["validation_notes"].append("å†å²æ•°æ®ä¸ºç©º")
                        elif summary.get("current_price") is None:
                            validation_info["data_quality"] = "poor"
                            validation_info["validation_notes"].append(
                                "ç¼ºå°‘å½“å‰ä»·æ ¼æ•°æ®"
                            )
                        else:
                            validation_info["validation_notes"].append(
                                f"è·å–åˆ°{summary.get('total_days', 0)}å¤©çš„å†å²æ•°æ®"
                            )

            elif tool_name == "get_financial_statements":
                if isinstance(result, dict) and "key_metrics" in result:
                    metrics = result["key_metrics"]
                    available_metrics = [
                        k for k, v in metrics.items() if v != "N/A" and v is not None
                    ]
                    if len(available_metrics) < 3:
                        validation_info["data_quality"] = "poor"
                        validation_info["validation_notes"].append("è´¢åŠ¡æŒ‡æ ‡æ•°æ®ä¸å®Œæ•´")
                    else:
                        validation_info["validation_notes"].append(
                            f"è·å–åˆ°{len(available_metrics)}ä¸ªæœ‰æ•ˆè´¢åŠ¡æŒ‡æ ‡"
                        )

            elif tool_name == "get_stock_news":
                if isinstance(result, list):
                    if len(result) == 0:
                        validation_info["data_quality"] = "poor"
                        validation_info["validation_notes"].append("æœªæ‰¾åˆ°ç›¸å…³æ–°é—»")
                    else:
                        validation_info["validation_notes"].append(
                            f"è·å–åˆ°{len(result)}æ¡æ–°é—»"
                        )

            elif tool_name == "calculate_technical_indicators":
                if isinstance(result, dict) and "indicators" in result:
                    indicators = result["indicators"]
                    valid_indicators = 0
                    for category, values in indicators.items():
                        if isinstance(values, dict):
                            valid_indicators += len(
                                [v for v in values.values() if v is not None]
                            )
                        elif values is not None:
                            valid_indicators += 1

                    if valid_indicators < 5:
                        validation_info["data_quality"] = "poor"
                        validation_info["validation_notes"].append("æŠ€æœ¯æŒ‡æ ‡æ•°æ®ä¸å®Œæ•´")
                    else:
                        validation_info["validation_notes"].append(
                            f"è®¡ç®—å‡º{valid_indicators}ä¸ªæœ‰æ•ˆæŠ€æœ¯æŒ‡æ ‡"
                        )

            # æ·»åŠ æ•°æ®æ—¶æ•ˆæ€§æ£€æŸ¥
            from datetime import datetime

            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            validation_info["data_timestamp"] = current_time
            validation_info["validation_notes"].append(f"æ•°æ®è·å–æ—¶é—´: {current_time}")

            logger.info(
                f"å·¥å…·{tool_name}æ•°æ®éªŒè¯å®Œæˆï¼Œè´¨é‡: {validation_info['data_quality']}"
            )
            return validation_info

        except Exception as e:
            logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
            validation_info["data_quality"] = "unknown"
            validation_info["validation_notes"].append(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return validation_info

    def analyze(
        self, user_query: str, max_steps: int = 5, step_callback=None
    ) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œè¿›è¡Œåˆ†æ"""
        logger.info(f"å¼€å§‹åˆ†æç”¨æˆ·æŸ¥è¯¢: {user_query}")
        self.conversation_history.append({"role": "user", "content": user_query})

        steps = []
        final_analysis = None
        total_tokens_used = 0

        for step in range(max_steps):
            logger.info(f"æ‰§è¡Œåˆ†ææ­¥éª¤ {step+1}/{max_steps}")
            # è°ƒç”¨å¤§æ¨¡å‹è·å–å“åº”
            logger.debug(f"å‘OpenAIå‘é€è¯·æ±‚ï¼Œæ¨¡å‹: {self.model_name}")
            response = self.openai_client.chat.completions.create(
                model=self.model_name, messages=self.conversation_history
            )

            # ç»Ÿè®¡tokenä½¿ç”¨é‡
            step_tokens = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens,
            }
            total_tokens_used += step_tokens["total_tokens"]

            llm_response = response.choices[0].message.content
            logger.info(
                f"OpenAI APIè°ƒç”¨å®Œæˆ - æ­¥éª¤{step+1} Tokenä½¿ç”¨: {step_tokens['prompt_tokens']} prompt + {step_tokens['completion_tokens']} completion = {step_tokens['total_tokens']} total"
            )
            logger.debug(f"æ”¶åˆ°OpenAIå“åº”: {llm_response}")
            self.conversation_history.append(
                {"role": "assistant", "content": llm_response}
            )

            # è®°å½•æ­¥éª¤
            step_data = {
                "step": step + 1,
                "llm_response": llm_response,
                "token_usage": step_tokens,
            }
            steps.append(step_data)

            # å®æ—¶å‘é€æ€è€ƒè¿‡ç¨‹
            if step_callback:
                # æå–ä¸åŒ…å«å·¥å…·è°ƒç”¨æ ‡è®°çš„éƒ¨åˆ†
                clean_response = llm_response
                tool_call_start = clean_response.find("<tool_call>")
                if tool_call_start != -1:
                    clean_response = clean_response[:tool_call_start].strip()

                if clean_response.strip():
                    step_callback(
                        {
                            "type": "thinking",
                            "content": f"ğŸ’­ æ­¥éª¤ {step+1}: {clean_response}",
                        }
                    )

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
            tool_call = self._parse_tool_call(llm_response)

            if not tool_call:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜åˆ†æå®Œæˆ
                logger.info("æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œåˆ†æå®Œæˆ")
                final_analysis = llm_response
                break

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {tool_call['name'] if tool_call else 'None'}")

            # å®æ—¶å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
            if step_callback and tool_call:
                tool_name = tool_call.get("name", "æœªçŸ¥å·¥å…·")
                tool_params = tool_call.get("parameters", {})

                # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆæè¿°
                if tool_name == "get_historical_data":
                    ticker = tool_params.get("ticker", "")
                    step_callback(
                        {
                            "type": "tool",
                            "content": f"ğŸ“Š æ­£åœ¨è·å– {ticker} çš„å†å²æ•°æ®...",
                        }
                    )
                elif tool_name == "get_financial_statements":
                    ticker = tool_params.get("ticker", "")
                    step_callback(
                        {
                            "type": "tool",
                            "content": f"ğŸ“ˆ æ­£åœ¨è·å– {ticker} çš„è´¢åŠ¡æŠ¥è¡¨...",
                        }
                    )
                elif tool_name == "get_news":
                    ticker = tool_params.get("ticker", "")
                    step_callback(
                        {
                            "type": "tool",
                            "content": f"ğŸ“° æ­£åœ¨è·å– {ticker} çš„æœ€æ–°æ–°é—»...",
                        }
                    )
                elif tool_name == "calculate_technical_indicators":
                    ticker = tool_params.get("ticker", "")
                    step_callback(
                        {
                            "type": "tool",
                            "content": f"ğŸ“‰ æ­£åœ¨è®¡ç®— {ticker} çš„æŠ€æœ¯æŒ‡æ ‡...",
                        }
                    )
                else:
                    step_callback(
                        {"type": "tool", "content": f"ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}"}
                    )

            tool_result = self._run_tool(tool_call)
            steps[-1]["tool_call"] = tool_call
            steps[-1]["tool_result"] = tool_result

            # è®°å½•å·¥å…·è°ƒç”¨çš„è¯¦ç»†æ—¥å¿—
            tool_log_data = {
                "tool_name": tool_call.get("name", "unknown"),
                "tool_parameters": tool_call.get("parameters", {}),
                "tool_execution_status": tool_result.get("status", "unknown"),
                "data_quality": tool_result.get("data_quality", "unknown"),
                "validation_notes": tool_result.get("validation_notes", []),
                "tool_result": tool_result.get("result", {}),
            }
            logger.info(
                f"å·¥å…·è°ƒç”¨è¯¦æƒ…: {json.dumps(tool_log_data, ensure_ascii=False, indent=2)}"
            )

            # å‘é€å·¥å…·æ‰§è¡Œå®Œæˆä¿¡æ¯
            if step_callback:
                step_callback(
                    {"type": "thinking", "content": "âœ… å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨åˆ†æç»“æœ..."}
                )

            # å°†å·¥å…·ç»“æœè¿”å›ç»™å¤§æ¨¡å‹
            # å¤„ç†å¯èƒ½åŒ…å«Timestampç±»å‹é”®çš„å­—å…¸
            def json_serializable(obj):
                import pandas as pd

                if isinstance(obj, dict):
                    return {str(k): json_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [json_serializable(i) for i in obj]
                elif isinstance(obj, pd.Timestamp):
                    return str(obj)
                else:
                    return obj

            serializable_result = json_serializable(tool_result)
            tool_result_msg = (
                f"å·¥å…·è°ƒç”¨ç»“æœ:\n{json.dumps(serializable_result, indent=2)}"
            )
            logger.debug(f"å·¥å…·è°ƒç”¨ç»“æœ: {json.dumps(serializable_result)}")
            self.conversation_history.append(
                {"role": "user", "content": tool_result_msg}
            )

        # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä½†è¿˜æ²¡æœ‰æœ€ç»ˆåˆ†æï¼Œè¯·æ±‚ä¸€ä¸ªæ€»ç»“
        if final_analysis is None:
            logger.info("è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ï¼Œè¯·æ±‚æœ€ç»ˆåˆ†ææ€»ç»“")
            summary_prompt = "è¯·åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œæä¾›ä¸€ä¸ªå®Œæ•´çš„åˆ†ææ€»ç»“å’ŒæŠ•èµ„å»ºè®®ã€‚ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚"
            self.conversation_history.append(
                {"role": "user", "content": summary_prompt}
            )

            response = self.openai_client.chat.completions.create(
                model=self.model_name, messages=self.conversation_history
            )

            # ç»Ÿè®¡æœ€ç»ˆæ€»ç»“çš„tokenä½¿ç”¨é‡
            final_tokens = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens,
            }
            total_tokens_used += final_tokens["total_tokens"]

            final_analysis = response.choices[0].message.content
            logger.info(
                f"æœ€ç»ˆåˆ†ææ€»ç»“å®Œæˆ - Tokenä½¿ç”¨: {final_tokens['prompt_tokens']} prompt + {final_tokens['completion_tokens']} completion = {final_tokens['total_tokens']} total"
            )

            # è®°å½•æœ€ç»ˆæ€»ç»“æ­¥éª¤
            steps.append(
                {
                    "step": len(steps) + 1,
                    "llm_response": final_analysis,
                    "token_usage": final_tokens,
                    "is_final_summary": True,
                }
            )

        # å‘é€æœ€ç»ˆåˆ†æç»“æœ
        if step_callback and final_analysis:
            step_callback({"type": "final", "content": final_analysis})

        # è®°å½•æ€»ä½“tokenä½¿ç”¨ç»Ÿè®¡
        logger.info(
            f"åˆ†æå®Œæˆ - æ€»Tokenæ¶ˆè€—: {total_tokens_used} tokensï¼Œå…±æ‰§è¡Œ{len(steps)}ä¸ªæ­¥éª¤"
        )

        return {
            "query": user_query,
            "steps": steps,
            "final_analysis": final_analysis,
            "completed": final_analysis is not None,
            "total_tokens_used": total_tokens_used,
            "steps_count": len(steps),
        }
